{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import sys  \n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "news_data_cleaned = pd.read_csv('news_data.csv')\n",
    "\n",
    "# Clean the data\n",
    "news_data_cleaned['text'] = news_data_cleaned['text'].fillna('')\n",
    "news_data_cleaned['categories'] = news_data_cleaned['categories'].fillna('')\n",
    "\n",
    "# Split categories into lists\n",
    "news_data_cleaned['categories_split'] = news_data_cleaned['categories'].apply(lambda x: x.split(','))\n",
    "\n",
    "# One-hot encode the categories using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "categories_onehot = mlb.fit_transform(news_data_cleaned['categories_split'])\n",
    "categories_df = pd.DataFrame(categories_onehot, columns=mlb.classes_)\n",
    "\n",
    "categories = [\n",
    "    'Greenhouse gas emissions', 'Carbon footprint', 'Exposure to companies active in the fossil fuel sector',\n",
    "    'Exposure to fossil fuels through real estate assets', 'Non-renewable energy consumption and production',\n",
    "    'Exposure to energy-inefficient real estate assets', 'Biodiversity/Nature Capital', 'Water', 'Pollution',\n",
    "    'Waste', 'Chemical', 'Land/agricultural practice', 'Oceans/seas practices', 'Raw materials consumption',\n",
    "    'UNGC principles', 'OECD guidelines', 'Workplace safety', 'Supplier management', 'Grievance mechanism',\n",
    "    'Whistleblower protection', 'Discrimination', 'Human Rights', 'Gender', 'Exposure to controversial weapons',\n",
    "    'Excessive CEO pay ratio', 'Corruption and bribery', 'Management structure', 'Employee relations',\n",
    "    'Remuneration of staff', 'Tax compliance'\n",
    "]\n",
    "\n",
    "full_data = pd.concat([news_data_cleaned[['text']], categories_df], axis=1)\n",
    "\n",
    "for category in categories:\n",
    "    if category not in full_data.columns:\n",
    "        full_data[category] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Tag  count  class_weight\n",
      "0                        Biodiversity/Nature Capital      8     31.375000\n",
      "1                                   Carbon footprint      7     35.857143\n",
      "2                                           Chemical     20     12.550000\n",
      "3                             Corruption and bribery      8     31.375000\n",
      "4   Exposure to companies active in the fossil fu...      2    125.500000\n"
     ]
    }
   ],
   "source": [
    "categories_df = pd.DataFrame(categories_onehot, columns=mlb.classes_)\n",
    "most_common_tags = pd.DataFrame(categories_df.sum(axis=0)).reset_index()\n",
    "most_common_tags.columns = ['Tag', 'count']\n",
    "most_common_tags = most_common_tags[most_common_tags['count'] > 0]\n",
    "\n",
    "# Calculate class weights for non-zero categories\n",
    "most_common_tags['class_weight'] = len(categories_df) / most_common_tags['count']\n",
    "class_weight = {}\n",
    "filtered_categories = []\n",
    "\n",
    "for index, label in enumerate(categories):\n",
    "    if label in most_common_tags['Tag'].values:\n",
    "        class_weight[index] = most_common_tags[most_common_tags['Tag'] == label]['class_weight'].values[0]\n",
    "        filtered_categories.append(label)  \n",
    "filtered_data = full_data[['text'] + filtered_categories]\n",
    "print(most_common_tags.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 200\n",
      "Validation dataset size: 25\n",
      "Test dataset size: 26\n"
     ]
    }
   ],
   "source": [
    "# Custom Dataset Class for filtered categories\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len, active_categories):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.df = df\n",
    "        self.text = df['text']\n",
    "        self.targets = self.df[active_categories].values\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'token_type_ids': inputs[\"token_type_ids\"].flatten(),\n",
    "            'targets': torch.FloatTensor(self.targets[index]),\n",
    "            'text': text  \n",
    "        }\n",
    "        \n",
    "# Split the full dataset into 80% train, 10% validation, and 10% test\n",
    "train_data, remaining_data = train_test_split(filtered_data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset the index for all the datasets\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "# Create Dataset instances using filtered categories\n",
    "train_dataset = CustomDataset(train_data, tokenizer, MAX_LEN, filtered_categories)\n",
    "valid_dataset = CustomDataset(val_data, tokenizer, MAX_LEN, filtered_categories)\n",
    "test_dataset = CustomDataset(test_data, tokenizer, MAX_LEN, filtered_categories)\n",
    "\n",
    "# DataLoaders for batching\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_data_loader = DataLoader(valid_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# Check the sizes of your training, validation, and test sets\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BERT-based model class\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, num_active_categories):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, num_active_categories)  \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        _, output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=False)\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "# Create model with the number of output categories\n",
    "num_active_categories = len(filtered_categories)  \n",
    "model = BERTClass(num_active_categories).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_active_categories = len(filtered_categories)\n",
    "model = BERTClass(num_active_categories)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)\n",
    "class_weight_tensor = torch.FloatTensor(list(class_weight.values())).to(device)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss(weight=class_weight_tensor)(outputs, targets)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckp(checkpoint_fpath, model, optimizer):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model that we want to load checkpoint parameters into       \n",
    "    optimizer: optimizer we defined in previous training\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_fpath)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    valid_loss_min = checkpoint['valid_loss_min']\n",
    "    return model, optimizer, checkpoint['epoch'], valid_loss_min.item()\n",
    "\n",
    "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
    "    \"\"\"\n",
    "    state: checkpoint we want to save\n",
    "    is_best: is this the best checkpoint; min validation loss\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    best_model_path: path to save best model\n",
    "    \"\"\"\n",
    "    f_path = checkpoint_path\n",
    "    torch.save(state, f_path)\n",
    "    if is_best:\n",
    "        best_fpath = best_model_path\n",
    "        shutil.copyfile(f_path, best_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs, training_loader, validation_loader, model, \n",
    "                optimizer, checkpoint_path, best_model_path):\n",
    "   \n",
    "    # Initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        model.train()\n",
    "        print(f'############# Epoch {epoch}: Training Start #############')\n",
    "\n",
    "        for batch_idx, data in enumerate(training_loader):\n",
    "            ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            optimizer.zero_grad()  \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            loss.backward()  \n",
    "            optimizer.step() \n",
    "            \n",
    "            train_loss += ((1 / (batch_idx + 1)) * (loss.item() - train_loss))  \n",
    "\n",
    "        print(f'############# Epoch {epoch}: Training End #############')\n",
    "        print(f'############# Epoch {epoch}: Validation Start #############')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  \n",
    "\n",
    "        val_targets = []  \n",
    "        val_outputs = []  \n",
    "\n",
    "        with torch.no_grad():  #\n",
    "            for batch_idx, data in enumerate(validation_loader):\n",
    "                ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "                mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "                token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "                targets = data['targets'].to(device, dtype=torch.float)\n",
    "\n",
    "                outputs = model(ids, mask, token_type_ids)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                valid_loss += ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))  \n",
    "\n",
    "                val_targets.extend(targets.cpu().detach().numpy().tolist())  \n",
    "                val_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist()) \n",
    "\n",
    "        print(f'############# Epoch {epoch}: Validation End #############')\n",
    "\n",
    "        # Calculate average losses\n",
    "        train_loss /= len(training_loader)\n",
    "        valid_loss /= len(validation_loader)\n",
    "        print(f'Epoch: {epoch} \\tAverage Training Loss: {train_loss:.6f} \\tAverage Validation Loss: {valid_loss:.6f}')\n",
    "\n",
    "        # Create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'valid_loss_min': valid_loss,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
    "        \n",
    "        # Save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving model ...')\n",
    "            save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "        print(f'############# Epoch {epoch} Done #############\\n')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"/Users/nicholastristan/Documents/multilabel_classification/curr_ckpt.pth\"\n",
    "best_model_path = \"/Users/nicholastristan/Documents/multilabel_classification/best_model.pt\"\n",
    "directory = os.path.dirname(ckpt_path)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Epoch 1: Training Start #############\n",
      "############# Epoch 1: Training End #############\n",
      "############# Epoch 1: Validation Start #############\n",
      "############# Epoch 1: Validation End #############\n",
      "Epoch: 1 \tAverage Training Loss: 4.574385 \tAverage Validation Loss: 27.138155\n",
      "Validation loss decreased (inf --> 27.138155). Saving model ...\n",
      "############# Epoch 1 Done #############\n",
      "\n",
      "############# Epoch 2: Training Start #############\n",
      "############# Epoch 2: Training End #############\n",
      "############# Epoch 2: Validation Start #############\n",
      "############# Epoch 2: Validation End #############\n",
      "Epoch: 2 \tAverage Training Loss: 3.593827 \tAverage Validation Loss: 21.578285\n",
      "Validation loss decreased (27.138155 --> 21.578285). Saving model ...\n",
      "############# Epoch 2 Done #############\n",
      "\n",
      "############# Epoch 3: Training Start #############\n",
      "############# Epoch 3: Training End #############\n",
      "############# Epoch 3: Validation Start #############\n",
      "############# Epoch 3: Validation End #############\n",
      "Epoch: 3 \tAverage Training Loss: 2.976772 \tAverage Validation Loss: 18.329252\n",
      "Validation loss decreased (21.578285 --> 18.329252). Saving model ...\n",
      "############# Epoch 3 Done #############\n",
      "\n",
      "############# Epoch 4: Training Start #############\n",
      "############# Epoch 4: Training End #############\n",
      "############# Epoch 4: Validation Start #############\n",
      "############# Epoch 4: Validation End #############\n",
      "Epoch: 4 \tAverage Training Loss: 2.611760 \tAverage Validation Loss: 16.266848\n",
      "Validation loss decreased (18.329252 --> 16.266848). Saving model ...\n",
      "############# Epoch 4 Done #############\n",
      "\n",
      "############# Epoch 5: Training Start #############\n",
      "############# Epoch 5: Training End #############\n",
      "############# Epoch 5: Validation Start #############\n",
      "############# Epoch 5: Validation End #############\n",
      "Epoch: 5 \tAverage Training Loss: 2.342910 \tAverage Validation Loss: 14.719577\n",
      "Validation loss decreased (16.266848 --> 14.719577). Saving model ...\n",
      "############# Epoch 5 Done #############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(EPOCHS, train_data_loader, val_data_loader, model, optimizer, ckpt_path, best_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@3: 0.0933\n",
      "Recall@3: 0.1300\n",
      "nDCG@3: 0.1809\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, data_loader, k=3):\n",
    "    model.eval()  \n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch.get('token_type_ids', None)\n",
    "            if token_type_ids is not None:\n",
    "                token_type_ids = token_type_ids.to(device)\n",
    "            \n",
    "            targets = batch['targets'].to(device)\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            logits = outputs[0] if isinstance(outputs, tuple) else outputs\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_outputs.append(probs.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    return np.vstack(all_outputs), np.vstack(all_targets)\n",
    "\n",
    "def precision_at_k(y_true, y_pred, k=3):\n",
    "    top_k_preds = np.argsort(-y_pred, axis=1)[:, :k] \n",
    "    precision_scores = []\n",
    "\n",
    "    for i in range(y_true.shape[0]):\n",
    "        top_k_labels = top_k_preds[i]\n",
    "        true_labels = np.where(y_true[i] == 1)[0]\n",
    "\n",
    "        correct = np.intersect1d(top_k_labels, true_labels).shape[0]\n",
    "        precision_scores.append(correct / k)\n",
    "\n",
    "    return np.mean(precision_scores)\n",
    "\n",
    "def recall_at_k(y_true, y_pred, k=3):\n",
    "    top_k_preds = np.argsort(-y_pred, axis=1)[:, :k]\n",
    "    recall_scores = []\n",
    "\n",
    "    for i in range(y_true.shape[0]):\n",
    "        top_k_labels = top_k_preds[i]\n",
    "        true_labels = np.where(y_true[i] == 1)[0]\n",
    "\n",
    "        correct = np.intersect1d(top_k_labels, true_labels).shape[0]\n",
    "        recall_scores.append(correct / len(true_labels) if len(true_labels) > 0 else 0)\n",
    "\n",
    "    return np.mean(recall_scores)\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k=3):\n",
    "    def dcg_at_k(relevance_scores):\n",
    "        return np.sum((2 ** relevance_scores - 1) / np.log2(np.arange(1, len(relevance_scores) + 1) + 1))\n",
    "\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for i in range(y_true.shape[0]):\n",
    "        top_k_preds = np.argsort(-y_pred[i])[:k]\n",
    "        relevance_scores = y_true[i, top_k_preds]\n",
    "        \n",
    "        dcg = dcg_at_k(relevance_scores)\n",
    "        ideal_dcg = dcg_at_k(np.sort(relevance_scores)[::-1])\n",
    "\n",
    "        ndcg_scores.append(dcg / ideal_dcg if ideal_dcg > 0 else 0)\n",
    "\n",
    "    return np.mean(ndcg_scores)\n",
    "\n",
    "y_pred, y_true = get_predictions(model, val_data_loader, k=3)\n",
    "precision_k = precision_at_k(y_true, y_pred, k=3)\n",
    "recall_k = recall_at_k(y_true, y_pred, k=3)\n",
    "ndcg_k = ndcg_at_k(y_true, y_pred, k=3)\n",
    "print(f'Precision@3: {precision_k:.4f}')\n",
    "print(f'Recall@3: {recall_k:.4f}')\n",
    "print(f'nDCG@3: {ndcg_k:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
